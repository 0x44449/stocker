# Project Memory

프로젝트의 방향성과 설계 결정을 기록합니다.
Architect가 설계 시 참고하는 문서입니다.

---

## 프로젝트 개요

**stocker** - 한국 주식 시장 뉴스 분석 파이프라인

### 핵심 비전

> 인스타/페북처럼 사람들 간의 피드가 아니라,
> **종목/기업의 히스토리 피드**를 볼 수 있는 서비스

### 원하는 기능

| # | 기능 | 핵심 |
|---|------|------|
| 1 | 관심종목 뉴스 모아보기 | 뉴스 ↔ 종목 연결 필요 |
| 2 | 주식 상황 설명 | 브리핑/요약 느낌 |
| 3 | 종목별 히스토리 타임라인 | 뉴스 + 가격 + 이벤트 시간순 |

### 구현 우선순위

```
1번 (관심종목 뉴스) → 가장 기초, 먼저
     ↓
3번 (종목 히스토리) → 1번 되면 자연스럽게 가능
     ↓
2번 (상황 설명) → 제일 어려움, 나중에
```

## 핵심 원칙

### 비용 최소화
- 외부 API 비용 없이 로컬에서 처리
- LLM: 로컬 Ollama 사용 (qwen2.5:7b)
- 임베딩: 로컬 모델 사용 (KURE-v1)
- 클라우드 서비스 최소화

### 단순함 우선
- 복잡한 아키텍처보다 동작하는 단순한 구조
- 필요할 때 확장, 미리 만들지 않음
- 개인 프로젝트이므로 빠른 개발 우선

## 시스템 구조

```
[뉴스 소스] → [Spring Boot API] → [PostgreSQL]
                                       ↓
                              [Python Analyzer] ← [Ollama]
```

### Spring Boot API (apps/api)
- 뉴스 크롤링 (KrxFileClient, NewsCrawlEngine 등)
- KRX 데이터 수집 (주가, 종목 마스터)
- REST API 제공

### Python Analyzer (apps/news-analyzer)
- LLM 기반 기업명 추출
- 벡터 임베딩 및 유사 뉴스 검색
- FastAPI로 API 제공

### Admin Web (apps/admin-web)
- 관리용 프론트엔드
- Next.js
- 기업명-종목 수동 매핑, 향후 관리 기능 확장

### 인프라
- Docker Compose로 로컬 배포
- PostgreSQL + pgvector

## 파이프라인 구조

```
[뉴스 원문]
     ↓
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Stage 1: 종목 연결
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  재료 추출:
    - LLM 기업명 추출
    - 종목코드 패턴
    - 인물명 → 소속 회사
    - 제품/브랜드 → 제조사
    - 자회사/계열사 관계
    - 섹터/산업 키워드
    - URL/기사 메타데이터
  
  벡터 활용:
    - 과거 유사 뉴스 참조
    - 기업 프로필 매칭
    - 뉴스 클러스터링
     ↓
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Stage 2: 뉴스 분류
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  실적, M&A, 신제품, 규제, 인사, 소송...
     ↓
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Stage 3: 감성/영향
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  긍정 / 부정 / 중립
     ↓
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Stage 4: 요약
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
  피드용 한줄 요약
     ↓
[가공 완료]
```

### Stage 1 상세: 종목 연결 재료

| 구분 | 방식 | 비고 |
|------|------|------|
| 직접 추출 | LLM 기업명 추출 | 핵심 |
| 직접 추출 | 종목코드 패턴 | 있으면 확실 |
| 연관 추론 | 인물명 → 소속 회사 | 마스터 데이터 필요 |
| 연관 추론 | 제품/브랜드 → 제조사 | 마스터 데이터 필요 |
| 연관 추론 | 자회사/계열사 관계 | 마스터 데이터 필요 |
| 간접 연결 | 섹터/산업 키워드 | 범위 넓음 |
| 메타데이터 | URL/기사 카테고리 | 출처 의존 |
| 벡터 | 과거 유사 뉴스 참조 | 데이터 쌓여야 효과 |
| 벡터 | 기업 프로필 매칭 | 프로필 구축 필요 |
| 벡터 | 뉴스 클러스터링 | 데이터 쌓여야 효과 |

### Stage 1 구현 순서

| 순서 | 항목 | 이유 |
|------|------|------|
| 1 | LLM 기업명 추출 | 마스터 데이터 없이 바로 시작 가능 |
| 2 | 종목코드 패턴 | 단순, 확실 |
| 3 | 벡터 (과거 뉴스) | 1번 결과 쌓이면 자연스럽게 가능 |

나머지는 마스터 데이터 구축되면 추가.

### 현재 구현 상태
- Stage 1 부분 구현: LLM 기업명 추출 (qwen2.5:7b)
- 임베딩: KURE-v1
- 유사 뉴스 검색: pgvector

### 벡터 활용 방안

**1. 종목 연결 전파**
```
[클러스터: 반도체 수출 규제 관련 뉴스 5건]
  - 뉴스A: 삼성전자 언급 ✅
  - 뉴스B: SK하이닉스 언급 ✅
  - 뉴스C: 기업명 없음 → 같은 클러스터니까 연결 가능
  - 뉴스D: "반도체 업계" 만 언급 → 연결 가능
  - 뉴스E: 기업명 없음 → 연결 가능
```

**2. 중복/유사 뉴스 처리**
```
같은 이슈 뉴스 10개
     ↓
피드에 다 보여줄 필요 없음
     ↓
대표 1개만 or "관련 뉴스 +9"
```

**3. 이슈 단위 파악**
```
개별 뉴스 → "삼성전자 뉴스 50건"
클러스터 → "삼성전자 관련 이슈 3건"
             - 실적 발표 (뉴스 20건)
             - 인사 이동 (뉴스 15건)
             - 신제품 (뉴스 15건)
```
피드에서 이슈 단위로 묶어서 보여줄 수 있음.

## 설계 결정 히스토리

### 2026-01-30: 로컬 LLM 선택
- **배경**: 뉴스에서 기업명 추출 필요
- **검토**: 키워드 매칭, NER 모델, 로컬 LLM
- **결정**: 로컬 LLM (qwen2.5:7b)
- **이유**: 약어(삼전), 띄어쓰기(삼성 전자) 등 문맥 이해 필요

### 2026-01-30: Python Analyzer 분리
- **배경**: Spring Boot에서 Ollama 연동이 복잡
- **결정**: Python FastAPI로 분석 서비스 분리
- **이유**: Python의 ML/NLP 생태계 활용, 역할 분리

### 2026-02-01: JPA Upsert 방식
- **배경**: 종목 마스터 데이터 daily upsert 필요
- **결정**: Native SQL 대신 saveAll() 사용
- **이유**: 소규모 데이터(~950건), 하루 1회, ORM 일관성 유지

### 2026-02-01: 기업명-종목 매칭 전략
- **배경**: LLM이 추출한 기업명을 종목코드와 연결해야 함
- **문제**: 유사도/포함관계로 매칭 시 오매칭 위험 (계열사, 유사 이름 등)
- **결정**: 
  - 자동 매칭은 정확 일치만 (name_kr, name_kr_short)
  - 미매칭은 수동으로 처리, 학습 데이터로 수집
  - 데이터 충분히 쌓이면 LLM 파인튜닝으로 자동화
- **테이블**: company_name_mapping (news_id, extracted_name, matched_stock_code, match_type, verified)

### 2026-02-03: 수동 매핑 테이블 재설계
- **배경**: company_name_mapping이 기능 대비 과도하게 복잡. extracted_name은 extraction_result에 이미 있어서 중복이고, match_type/verified/feedback 등 학습 파이프라인용 컬럼이 현 단계에서 불필요
- **결정**:
  - company_name_mapping 제거
  - `news_stock_manual_mapping` (news_id UNIQUE, stock_codes JSONB, feedback TEXT) - 뉴스 1건 = 1 row로 종목 연결 + 피드백 통합
- **이유**: LLM 추출(extraction_result)과 사람 검수(manual_mapping)를 분리. 테이블 1개로 단순화, 종목은 JSONB 배열로 저장

---

## Stage 1 매칭 아이디어 풀 (2026-02-04 브레인스토밍)

### 핵심 방향

지금은 종목 매핑 데이터를 쌍는 것이 우선. 데이터가 쌍이면 벡터 전파, 키워드 연관, 종목 프로필, 파인튜닝 등이 자연스럽게 가능해진다.

### 아이디어 목록

| # | 아이디어 | 설명 | 비고 |
|---|--------|------|------|
| A | 룰 기반 전처리 | 종목코드 패턴(6자리), stock_master 사전 매칭 | LLM 앞단에서 확실한 것 먼저 처리 |
| B | 별칭/약어 사전 | "삼전", "LG엔솔" 등 점진적 축적 | 수동 매핑에서 패턴 발견 시 추가 |
| C | 역방향 접근 | 종목별 "키워드 프로필"을 만들어두고 뉴스를 거기에 매칭 | 종목이 950개로 고정이라 관리 용이 |
| D | 주가 반응 역이용 | 뉴스 발행 전후 비정상 주가 변동 종목을 후보로 | published_at + stock_price_daily_raw 활용 |
| E | DART 공시 매칭 | 공시는 종목코드 확정. 공시-뉴스 유사도로 뉴스에 종목 연결 | DART OpenAPI 무료 |
| F | ETF 구성종목 = 테마 사전 | "2차전지" 언급 시 ETF 구성종목이 후보군 | KRX에서 데이터 확보 가능 |
| G | 종토방/커뮤니티 별칭 수집 | 종목별 토론방에서 자주 등장하는 비정식 명칭 수집 | 종목별로 분류되어 있어 역방향 검출 가능 |
| H | 나무위키 기업 정보 | 계열사, 제품, 임원 등 관계 데이터 대량 확보 | 문서 구조가 정형화되어 있어 파싱 수월 |
| I | 뉴스 출처/기자 패턴 | 기자별 담당 업종, URL 구조의 카테고리 정보 | press 필드 이미 있음 |
| J | RAG — LLM 컨텍스트 강화 | 종목 목록, 과거 유사 뉴스 매핑 결과, 섹터별 종목 후보군 제공 | 환각 방지 + 정확도 향상 |
| K | 벡터 활용 | 유사 뉴스 전파, 종목 프로필 벡터, 클러스터링 | 임베딩 인프라 이미 있음 |
| L | 파인튜닝 | 매핑 데이터 충분히 쌍인 후 LLM 학습 | 지금은 때가 아님, 데이터 쌍이면 자연스럽게 |
| M | 키워드 연관 강도 | 형태소 분석으로 명사 추출 + 매핑된 종목과 동시출현 통계 | 종목 매핑이 먼저 쌍여야 의미 있음 |
| N | 동시 출현 네트워크 | 같은 뉴스에 자주 같이 나오는 종목들 → 종목 클러스터 자동 생성 | 한 종목만 잡히면 같은 클러스터로 확장 |
| O | Weak Supervision | 단순 규칙 여러 개 조합으로 노이즈 있지만 대량의 라벨 생성 | 노가다 최소화 |
| P | 능동 학습 (Active Learning) | 모델이 확신 없는 뉴스를 우선 보여주어 노가다 효율 극대화 | 수동 매핑 UI와 연계 |
| Q | 외부 라벨 데이터 활용 | 다음 금융 등 종목별 태깅된 뉴스를 씨앗 데이터로 | 학습데이터, 종목 프로필, 별칭 사전 등 다용도 |

### 3계층 구조

아이디어들은 독립적이 아니라 세 계층으로 나뉘어 서로 재료를 공급하고 강화하는 구조다.

#### Layer 1: 데이터 구축 — 매칭에 쓸 재료를 모으는 계층

| 아이디어 | 생성하는 데이터 | 공급 대상 (Layer 2) |
|---------|--------------|------------------|
| 나무위키(H) | 인물/제품/계열사 관계 | 역방향 프로필(C), 별칭 사전(B) |
| ETF(F) | 테마/섹터별 종목 그룹 | 역방향 프로필(C), RAG 후보군(J) |
| 종토방(G) | 비정식 별칭/약어 | 별칭 사전(B) |
| 외부 라벨(Q) | 뉴스-종목 정답 쌍 | 파인튜닝(L), 역방향 프로필(C), 별칭 사전(B) |
| DART(E) | 공시-뉴스 매칭 쌍 | 시간 기반 매칭 힌트 |

Layer 1은 한 번 구축하면 Layer 2의 거의 모든 방법에 재료를 공급한다. 특히 외부 라벨(Q)은 한 소스로 여러 곳에 쓸 수 있어 가성비가 좋다.

#### Layer 2: 매칭 실행 — 실제로 뉴스에 종목을 붙이는 계층

| 아이디어 | 역할 | 성격 |
|---------|------|------|
| 룰 기반(A) + 별칭(B) | 확실한 것을 빠르고 싸게 잡기 | 핵심 |
| 역방향 프로필(C) | 종목 측에서 뉴스를 매칭 | 핵심 |
| RAG(J) + 벡터(K) | LLM이 판단할 때 정확도 향상 | 보강 |
| 주가 반응(D) | 시간 기반 후보 종목 제시 | 보조 힌트 |
| 기자/출처(I) | 담당 업종 기반 후보 제시 | 보조 힌트 |
| DART 공시(E) | 시간+내용 유사도로 뉴스-공시 연결 | 보조 힌트 |

핵심 방법으로 대부분 잡고, 보강/힌트로 confidence를 올리는 구조.

#### Layer 3: 학습/개선 — Layer 2 결과가 쌍이면서 열리는 계층

| 아이디어 | 활성화 조건 | 효과 |
|---------|------------|------|
| 키워드 연관(M) | 매핑 데이터 축적 | 매핑된 종목과 동반 키워드로 미매칭 뉴스 추론 |
| 동시출현 네트워크(N) | 매핑 데이터 축적 | 종목 클러스터로 확장 매칭 |
| 능동 학습(P) | 수동 매핑 UI | 모델이 확신 없는 것 우선으로 보여주어 노가다 효율화 |
| Weak Supervision(O) | 룰 여러 개 조합 | 노이즈 있지만 대량 라벨로 수동 작업 대체 |
| 파인튜닝(L) | 매핑 데이터 충분 | LLM 자체를 학습시켜 최종 자동화 |

Layer 3은 Layer 2의 결과를 먹고 성장하고, 다시 Layer 2의 정확도를 높이는 피드백 루프.

#### 순환 구조

```
Layer 1 (데이터 구축)
  │  재료 공급
  ▼
Layer 2 (매칭 실행) ─── 매핑 결과 축적 ───┐
  ▲                                    │
  │  정확도 향상                      ▼
  └───────────── Layer 3 (학습/개선)
```

**피드백 루프 상세:**
- 키워드 연관(M) → 역방향 프로필(C) 갱신
- 동시출현(N) → 벡터 전파(K) 정확도 향상
- Weak Supervision(O) → 파인튜닝(L) 학습 데이터 확보
- 파인튜닝(L) → Layer 2 LLM 정확도 전체 향상

### 2026-02-10: news_extraction 테이블 재설계
- **배경**: 기존 `news_company_extraction` + `news_company_extraction_result` 2테이블 구조가 불필요하게 복잡하고, extraction_result에서 데이터를 뽑으려면 extraction을 거쳐야 하는 불필요한 JOIN 발생. LLM 결과도 신뢰할 수 없는 상태.
- **결정**:
  - 새 `news_extraction` 테이블 1개로 통합
  - keywords는 JSONB 배열로 저장 (`["삼성전자", "SK하이닉스"]`)
  - llm_model, prompt_version 저장하여 모델/프롬프트별 추출 이력 관리
  - llm_response에 LLM 원본 응답 저장 (디버깅용)
  - news_id UNIQUE 아님 — 같은 뉴스를 다른 모델로 여러 번 추출 가능
- **이유**: 파이프라인 각 모듈이 자기 결과를 독립적으로 저장하는 구조. extraction은 키워드 추출만 담당, 종목 매칭은 다음 모듈의 책임
- **기존 테이블**: `news_company_extraction`, `news_company_extraction_result`는 삭제하지 않고 유지 (HeadlineService 등에서 참조 중)

### 2026-02-10: 헤드라인 API를 news_extraction 기반으로 변경
- **배경**: HeadlineService가 기존 extraction 테이블 기반이었으나 새 테이블로 전환 필요
- **결정**:
  - news_extraction의 keywords JSONB를 Java에서 풀어서 카운팅 (JSONB 집계는 native SQL 필요하므로)
  - stock_master의 name_kr, name_kr_short와 매칭되는 키워드만 카운팅
  - DB에서 날짜/모델/프롬프트 필터링, Java에서 매칭/집계 (CODING_DECISIONS 일관)
  - llm_model, prompt_version은 하드코딩 (탐색 단계)
- **이유**: QueryDSL로 JSONB 배열 처리 불가, 나중에 스케줄러 배치로 전환 시 DB Function 등으로 최적화 가능

## 향후 방향

### Stage 1 완성
- 종목 마스터 ↔ 추출 기업명 매칭 로직
- 종목코드 패턴 인식
- 인물/제품/브랜드 매핑 데이터

### Stage 2~4 설계
- 뉴스 분류 카테고리 정의
- 감성 분석 방식
- 요약 생성 프롬프트

---

*이 문서는 Architect가 지속적으로 업데이트합니다.*
